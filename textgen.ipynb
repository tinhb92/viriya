{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jupyter/.fastai/data/imdb_sample')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is some merit in this view, but it\\'s also true that no one forced Hindus and Muslims in the region to mistreat each other as they did around the time of partition. It seems more likely that the British simply saw the tensions between the religions and were clever enough to exploit them to their own ends.<br /><br />The result is that there is much cruelty and inhumanity in the situation and this is very unpleasant to remember and to see on the screen. But it is never painted as a black-and-white case. There is baseness and nobility on both sides, and also the hope for change in the younger generation.<br /><br />There is redemption of a sort, in the end, when Puro has to make a hard choice between a man who has ruined her life, but also truly loved her, and her family which has disowned her, then later come looking for her. But by that point, she has no option that is without great pain for her.<br /><br />This film carries the message that both Muslims and Hindus have their grave faults, and also that both can be dignified and caring people. The reality of partition makes that realisation all the more wrenching, since there can never be real reconciliation across the India/Pakistan border. In that sense, it is similar to \"Mr & Mrs Iyer\".<br /><br />In the end, we were glad to have seen the film, even though the resolution was heartbreaking. If the UK and US could deal with their own histories of racism with this kind of frankness, they would certainly be better off.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'texts.csv', header=None)\n",
    "example_text = df.iloc[2][1]; example_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxmaj this is a extremely well - made film . xxmaj the acting , script and camera - work are all first - rate . xxmaj the music is good , too , though it is mostly early in the film , when things are still relatively cheery . xxmaj there are no really superstars in the cast , though several faces will be familiar . xxmaj the entire cast does an excellent job with the script . \\n \\n  xxmaj but it is hard to watch , because there is no good end to a situation like the one presented . xxmaj it is now fashionable to blame the xxmaj british for setting xxmaj hindus and xxmaj muslims against each other , and then cruelly separating them into two countries . xxmaj there is some merit in this view , but it \\'s also true that no one forced xxmaj hindus and xxmaj muslims in the region to mistreat each other as they did around the time of partition . xxmaj it seems more likely that the xxmaj british simply saw the tensions between the religions and were clever enough to exploit them to their own ends . \\n \\n  xxmaj the result is that there is much cruelty and inhumanity in the situation and this is very unpleasant to remember and to see on the screen . xxmaj but it is never painted as a black - and - white case . xxmaj there is baseness and nobility on both sides , and also the hope for change in the younger generation . \\n \\n  xxmaj there is redemption of a sort , in the end , when xxmaj puro has to make a hard choice between a man who has ruined her life , but also truly loved her , and her family which has disowned her , then later come looking for her . xxmaj but by that point , she has no option that is without great pain for her . \\n \\n  xxmaj this film carries the message that both xxmaj muslims and xxmaj hindus have their grave faults , and also that both can be dignified and caring people . xxmaj the reality of partition makes that realisation all the more wrenching , since there can never be real reconciliation across the xxmaj india / xxmaj pakistan border . xxmaj in that sense , it is similar to \" xxmaj mr & xxmaj mrs xxmaj iyer \" . \\n \\n  xxmaj in the end , we were glad to have seen the film , even though the resolution was heartbreaking . xxmaj if the xxup uk and xxup us could deal with their own histories of racism with this kind of frankness , they would certainly be better off .'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tok = SpacyTokenizer('en')\n",
    "' '.join(tokenizer.process_text(example_text, tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inconsistent use of spaces.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_useless_spaces(\"Inconsistent   use  of     spaces.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "        self.counter = collections.Counter()\n",
    "        self.total = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1\n",
    "\n",
    "        token_id = self.word2idx[word]\n",
    "        self.counter[token_id] += 1\n",
    "        self.total += 1\n",
    "        return token_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)\n",
    "\n",
    "\n",
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
    "        self.num_tokens = len(self.dictionary)\n",
    "\n",
    "    def tokenize(self, path):\n",
    "        \"\"\"Tokenizes a text file.\"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        # Add words to the dictionary\n",
    "        with open(path, 'r') as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                tokens += len(words)\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "\n",
    "        # Tokenize file content\n",
    "        with open(path, 'r') as f:\n",
    "            ids = torch.LongTensor(tokens)\n",
    "            token = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    ids[token] = self.dictionary.word2idx[word]\n",
    "                    token += 1\n",
    "\n",
    "        return ids\n",
    "    \n",
    "# https://github.com/fastai/fastai_docs/blob/master/dev_nb/007_wikitext_2.ipynb\n",
    "# download data from https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n",
    "EOS = '\\n'\n",
    "PATH=Path('')\n",
    "\n",
    "def read_file(filename):\n",
    "    tokens = []\n",
    "    with open(PATH/filename, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            tokens.append(line.split() + [EOS])\n",
    "    return np.array(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = read_file('train.txt')\n",
    "valid_tok = read_file('valid.txt')\n",
    "test_tok = read_file('test.txt')\n",
    "\n",
    "# cor = Corpus('')\n",
    "# voc = Vocab(cor.dictionary.idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(train_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in a for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602169"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flat_list)\n",
    "# 600k tokens\n",
    "# * 2 ~ ptb\n",
    "# * 5 ~ wikitext-2\n",
    "# * 300 ~ wikitext-103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Dear', 'friends,', 'today', 'is', 'the', '13th', 'of', 'August,', '1996,', 'and', 'we', 'are', 'in', 'the', 'Upper', 'Hamlet.', 'We', 'are', 'going', 'to', 'speak', 'English.']),\n",
       "       list([]),\n",
       "       list(['The', 'other', 'day', 'after', 'I', 'spoke', 'about', 'the', 'practice', 'of', 'the', 'four', 'mantras.', 'I', 'said', 'that', 'the', 'fourth', 'mantra', 'is', 'more', 'difficult,', 'so', 'I', 'did', 'not', 'talk', 'about', 'it.', 'In', 'fact', 'it', 'is', 'difficult,', 'but', 'not', 'so', 'difficult.', 'After', 'the', 'Dharma', 'talk,', 'when', 'we', 'were', 'about', 'to', 'do', 'walking', 'meditation,', 'there', 'was', 'a', 'gentleman', 'who', 'stopped', 'me', 'on', 'my', 'way', 'and', 'asked', 'me', 'about', 'the', 'fourth', 'mantra.', 'He', 'was', 'very', 'eager', 'to', 'learn', 'and', 'to', 'practice', 'the', 'fourth', 'mantra.', 'He', 'was', 'very', 'curious,', 'because', 'I', 'had', 'said', 'that', 'the', 'fourth', 'mantra', 'is', 'more', 'difficult.', 'But', 'after', 'that', 'I', 'thought', 'it', 'over,', 'and', 'I', 'thought', 'that', 'the', 'children', 'are', 'able', 'to', 'understand', 'and', 'practice', 'the', 'fourth', 'mantra,', 'also.', 'So', 'today', 'I', 'am', 'going', 'to', 'tell', 'them', 'how', 'to', 'practice', 'the', 'fourth', 'mantra.']),\n",
       "       list([]), ...,\n",
       "       list(['So', 'please', 'do', 'use', 'your', 'intelligence,', 'your', 'power', 'of', 'organisation,', 'in', 'order', 'to', 'arrange', 'this', 'because', 'Sangha', 'building', 'is', 'the', 'most', 'noble', 'task.', 'The', 'most', 'precious', 'thing', 'we', 'can', 'offer', 'to', 'our', 'society', 'is', 'Sangha.', 'So', 'everyone', 'has', 'to', 'learn', 'to', 'be', 'a', 'Sangha-builder.', 'There', 'are', 'many', 'monks,', 'nuns', 'and', 'lay', 'people', 'who', 'are', 'excellent', 'Dharma', 'teachers', '–', 'who', 'can', 'teach', 'Buddhism', 'very', 'well', '–', 'in', 'Vietnam', 'and', 'in', 'other', 'countries,', 'but', 'not', 'many', 'have', 'the', 'skill', 'of', 'Sangha', 'building.']),\n",
       "       list([]),\n",
       "       list(['My', 'fixation,', 'my', 'desire', 'is', 'that', 'every', 'OI', 'Member', 'should', 'learn', 'the', 'art', 'of', 'Sangha', 'building', 'because', 'Sangha', 'building', 'should', 'bring', 'you', 'a', 'lot', 'of', 'happiness.', 'With', 'Sangha', 'building', 'you', 'acquire', 'a', 'lot', 'of', 'merit', 'because', 'what', 'we', 'need', 'desperately', 'in', 'our', 'society', 'is', 'Sangha', 'where', 'people', 'can', 'come', 'and', 'feel', 'embraced', 'and', 'feel', 'understood', 'and', 'learn', 'to', 'see', 'the', 'path', 'of', 'emancipation.', 'A', 'true', 'Sangha', 'is', 'what', 'we', 'need', 'because', 'a', 'true', 'Sangha', 'always', 'carries', 'within', 'itself', 'the', 'Buddha', 'and', 'the', 'living', 'Dharma.', 'It', 'is', 'the', 'living', 'Dharma', 'that', 'makes', 'the', 'Sangha', 'into', 'a', 'true', 'Sangha,', 'a', 'living', 'refuge', 'for', 'us', 'and', 'for', 'our', 'society.', 'So', 'if', 'you', 'have', 'time', 'left', 'for', 'discussion,', 'please', 'give', 'your', 'attention', 'to', 'the', 'questions', 'of', 'training', 'and', 'Sangha', 'building.']),\n",
       "       list([])], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1080000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36000*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 256\n",
    "bptt = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (TextList.from_folder('')\n",
    "            .split_by_files('valid.txt')\n",
    "            .label_for_lm()           \n",
    "            .databunch(bs=bs, num_workers=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = TextLMDataBunch.from_tokens('data', \n",
    "                                  trn_tok = train_tok, trn_lbls = None,\n",
    "                                  val_tok = valid_tok, val_lbls=None,\n",
    "                                  tst_tok = test_tok, \n",
    "#                                   vocab = voc,\n",
    "                                  bs = bs, bptt = bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        TextLMDataBunch\n",
       "\u001b[0;31mString form:\u001b[0m\n",
       "TextLMDataBunch;\n",
       "           \n",
       "           Train: LabelList (4 items)\n",
       "           x: LMTextList\n",
       "           xxbos xxunk xxmaj contents\n",
       "           xxmaj no <...>  the questions of training and xxmaj sangha building .\n",
       "           \n",
       "           \n",
       "           y: LMLabelList\n",
       "           ,\n",
       "           Path: .;\n",
       "           \n",
       "           Test: None\n",
       "\u001b[0;31mFile:\u001b[0m        /opt/anaconda3/lib/python3.7/site-packages/fastai/text/data.py\n",
       "\u001b[0;31mDocstring:\u001b[0m   Create a `TextDataBunch` suitable for training a language model.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [] list has some method\n",
    "# voc.itos is a list so it has those default method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelList (58665 items)\n",
       "x: LMTextList\n",
       "\n",
       ",\n",
       ",\n",
       ",\n",
       ",\n",
       "\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: data"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxmaj when we ’re eating , we \\n  know that we are eating . xxmaj when we open a \\n  door , we know that we ’re opening a door . xxmaj our \\n  mind is with our actions . \\n  xxmaj when you put a piece of fruit into your \\n  mouth , all you need is a little bit of mindfulness \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>’ll have joy . \\n  xxup xxunk \\n \\n \\n  xxmaj the xxmaj planet xxmaj is xxmaj us \\n  xxmaj our food comes from this beautiful planet . xxmaj the \\n  xxmaj earth is inside of us , in each morsel of food , in \\n  the air we breathe , in the water that we drink \\n  and that flows through us .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>to be shared with young \\n  people before a meal , but they can be enjoyed \\n  by xxunk . \\n  1 . \u0007this food is the gift of the whole universe : \\n  the xxmaj earth , the sky , the rain , and the sun . \\n  2 . xxup w\u0007 e thank the people who have made this \\n  food ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>health , in the xxunk incidence of heart attacks , \\n  cancer , and other fatal diseases . xxmaj the average person \\n  looking out on this ever - changing , seemingly xxunk \\n  world sees anything but natural karmic laws at work , \\n  nor does he perceive the unity and harmony under- \\n  lying this constant and inevitable change . xxmaj if anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>xxmaj using \\n \\n \\n  xxup awareness xxup of xxup being 21 \\n  the telephone , i wish that all living beings should free \\n  themselves of doubt and prejudice in order that com- \\n  munication between them should be readily estab- \\n  lished . \" \\n  xxmaj when i was seventeen years xxunk , i thought that the \\n  xxmaj little xxmaj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need to avoid using \\n when not end of line\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(data, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.899552</td>\n",
       "      <td>3.569257</td>\n",
       "      <td>0.295536</td>\n",
       "      <td>01:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.399759</td>\n",
       "      <td>3.439830</td>\n",
       "      <td>0.318359</td>\n",
       "      <td>02:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.191141</td>\n",
       "      <td>3.534486</td>\n",
       "      <td>0.279074</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('../viriya_deploy/tnh.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"Practicing Concentration\"\n",
    "N_WORDS = 100\n",
    "N_SENTENCES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger is good. Anger is good . It is a \n",
      "  good example . It is a good way to be able to be \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('Anger is good.', n_words=20, beam_sz=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Practicing Concentration Mindfulness Training \n",
      "  While not practicing or practicing meditation , Bodhisattva ’s Friend \n",
      "  Mindfulness Training \n",
      "  In the United States , the First Mindfulness Training ( U.S. ) is an occasion for a meditation \n",
      "  on Awakening . There are \n",
      "  several books in the American Buddhist \n",
      "  Order of the Holy Spirit , such as Buddhist Meditation , Mindfulness and Meditation , and First Mindfulness Training , you have\n",
      "Practicing Concentration , Meditation on Walking , and Meditation on the Nature of Mindfulness . \n",
      "  The Five Factors of Awakening \n",
      "  The Five Factors of Awakening \n",
      "  The Three Factors of Awakening \n",
      "  The Five Realizations of Atman \n",
      "  The first three Trainings were preached by Living Beings in the Fifth \n",
      "  Mindfulness Training . The second part , of course , vision of the \n",
      "  Four Foundations of\n",
      "Practicing Concentration \n",
      "  The CONTINUING CONCENTRATION BREATH and Concentration Training ( SET ) , Mindfulness Training ( Follow the Teachings of The Great Beings ) , M. BE CONSTANTLY MINDFUL Breathing and Breathing Breathing \n",
      "  in Action , Mindfulness of Mindfulness , Breathing , and Breathing \n",
      "  Breathing in , i Calm Breathing in a Deep Meditation \n",
      "  Breathing in , i see the Four Gems \n",
      " \n",
      "Practicing Concentration \n",
      "  means to used a Christian \n",
      "  word to describe our daily lives . To see that the Buddha had been asked to develop a simple \n",
      "  system of mindfulness . The gentle and \n",
      "  serene nature of his movements often helped him in order to \n",
      "  transform his true nature . He was \n",
      "  not a good teacher , but to be \n",
      "  as quick as a he . His teacher wanted to be a teacher . He had never taught Buddhism without \n",
      "  Western thought . He would\n",
      "Practicing Concentration Meditation \n",
      "  After attaining a Buddhist state of meditation , the Master decided to reject his teaching . In Buddhism , he points out the \n",
      "  possibility of sitting outside the Buddha ’s chambers . He \n",
      "  said , “ Just just in our life , we can not be \n",
      "  caught up in a conflict . The Buddha is not alone . Everyone \n",
      "  is the same one at the same time . His life is still \n",
      "  very peaceful . We are so lucky\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using from folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger is good. Anger is good . It is a \n",
      "  very simple , simple , and simple way of living . It is a\n"
     ]
    }
   ],
   "source": [
    "print(learn.beam_search('Anger is good.', n_words=20, beam_sz=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Practicing Concentration \n",
      "  In the West , Genetic Awakening , The Way of Enlightenment \n",
      "  Every year , the Buddha delivers the Eight Realizations of Awakening . The Sutra on the Sangha of Mindfulness , a \n",
      "  box set of five full - length four - legged chairs is also available at the Center for the Present Moment . It contains the Sutra on Mindfulness , the \n",
      "  Complete Sutra on the Five Gates of\n",
      "Practicing Concentration Knots , Noble Truths , and Noble Truths . \n",
      "  The first equivalents of Dharma talk are Dharma talks and Reconciliation Talks from Buddhist monks . These \n",
      "  are mostly reserved for us . The first is a Buddhist teaching . This \n",
      "  is the first full - length talk of the Dharma . The first is \n",
      "  the Dharma talk . First , \n",
      "  the second training is to sit down and give the Dharma to the community .\n",
      "Practicing Concentration Life \n",
      "  The Five Practices of Mindfulness Training \n",
      "  Training for Training \n",
      "  Training training \n",
      "  Training is a training for training . In the training , training , and training , it is \n",
      "  training for both Training Training and Training . \n",
      "  Training Training \n",
      "  Training for Training , Training \n",
      "  Training \n",
      "  Training Exercises , Training and Training \n",
      "  Training Training \n",
      "  Training Training Training ( Training\n",
      "Practicing Concentration On The Problem \n",
      "  The Practitioner is a Buddhist Master who \n",
      "  founded the Buddha 's teaching and taught \n",
      "  him about the Four Noble Truths . He co - founded the Buddhist Buddhist Institute , known as Buddhist Institute , and was founded in an attempt to improve the lives of \n",
      "  children , society , and society . He lived in the West for seven years , and the sugar he \n",
      "  drank and drank in the \n",
      "  first\n",
      "Practicing Concentration , Mindfulness , Understanding , Love , and Craving in Our Community \n",
      "  We do not understand our roots and practice \n",
      "  them in terms of energy and concentration . \n",
      "  We ARE ALIVE : a Guide to Transformation and Healing \n",
      "  Chapter Twenty - Seven : The Well - Being of Mindfulness \n",
      "  Breathing in , Breathing in , i See My Water \n",
      "  Breathing in , i am aware of my breathing\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger Chapter West - said, words. The Buddha told the Buddha that the Buddha had preparing them for a special meal in the future. The Buddha said, Only our friend King Bimbisara is a great All a spiritual Rahula, and the senior bhikkhu in his nation would be the Buddha’s The\n",
      "Anger you are a long time in your daily heart. If you are fully awakened and at that moment you are suddenly the same or Buddha, I will never forget that you are I take the time to tell you about the Buddha in the very nature of his own body,\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tmp/tmpm4gg0br_', <http.client.HTTPMessage at 0x7fd91b4d4eb8>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "...\n",
    "# Download the file from `url` and save it locally under `file_name`:\n",
    "urllib.request.urlretrieve(url='https://drive.google.com/uc?export=download&id=1aONdl2-puQYv6LylrPolIWKE269kj6mL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download the file from `url` and save it locally under `file_name`:\n",
    "with urllib.request.urlopen(url='https://drive.google.com/uc?export=download&id=1aONdl2-puQYv6LylrPolIWKE269kj6mL') as response, open('t.pkl', 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Retrieve a URL into a temporary location on disk.\n",
       "\n",
       "Requires a URL argument. If a filename is passed, it is used as\n",
       "the temporary file location. The reporthook argument should be\n",
       "a callable that accepts a block number, a read size, and the\n",
       "total file size of the URL target. The data argument should be\n",
       "valid URL encoded data.\n",
       "\n",
       "If a filename is passed and the URL points to a local resource,\n",
       "the result is a copy from local file to new file.\n",
       "\n",
       "Returns a tuple containing the path to the newly created\n",
       "data file as well as the resulting HTTPMessage object.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/anaconda3/lib/python3.7/urllib/request.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?urllib.request.urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "html = response.read()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
